import numpyimport scipy.optimizefrom numpy.linalg import norm import lib.model_evaluation as evdef vrow(v):    return v.reshape((1, v.size))def vcol(v):    return v.reshape((v.size, 1))def JDual(alpha,H):    grad = numpy.dot(H, alpha) - numpy.ones(H.shape[1])    return ((1/2)*numpy.dot(numpy.dot(alpha.T, H), alpha)-numpy.dot(alpha.T, numpy.ones(H.shape[1])), grad)def dualForm(DT, LT, C, K):        #C is un pper bound of alpha_i.    #K. The sample x_i used into function is obtained by column vector[x_i,K],the default is 1.        new_row=(numpy.zeros(DT.shape[1]))+K  # Define a new row of K values    DT_new = numpy.vstack([DT, new_row])  # Define the new Dataset using the old DT and concatenating with a new row of K values        Z=numpy.zeros(LT.shape)  # Define the Z array that will contain all the z_i values    Z[LT==1]=1               # Using the class label we assign 1 or -1    Z[LT==0]=-1              # Using the class label we assign 1 or -1            H=numpy.dot(DT_new.T,DT_new)  # Calculate the H Matrix    H=vcol(Z)*vrow(Z)*H         # H_ij= z_i * z_j * x_i.T * x_j        x0=numpy.zeros(DT.shape[1])   # Define x0 as a vector of all 0        b=[(0,C)]*DT.shape[1]         # Define the bounds for all alpha_i that we have to determinate            best_alphas, _, _=scipy.optimize.fmin_l_bfgs_b(JDual, x0, args=(H,), bounds=b,factr=1.0) # Calculate the optimization variable        w = numpy.dot(DT_new,vcol(best_alphas)*vcol(Z))        return w    def kernelPoly(DT, LT, K, C, d, c):    return 0def kernelRBF(DT, LT, gamma, K, C):    return 0#------------------##  SVM classifier  ##------------------#def SVM(DT, LT, DE, gamma=1.0, C=1.0, K=1.0, c=0, d=2, mode="linear" ):    if (mode == "linear"):        w=dualForm(DT,LT,C,K)        DE = numpy.vstack([DE, numpy.zeros(DE.shape[1])+K])        S = numpy.dot(w.T, DE)        LabelPredicted = 1*(S > 0)        #LabelPredicted[LabelPredicted == 0] = -1        return S.ravel(),LabelPredicted            if (mode == "poly"):        kernelPoly(DT, LT, K, C, d, c)            if (mode == "RBF"):        kernelRBF(DT, LT, gamma, K, C)            return 0#------------------------##  Kfold implementation  ##------------------------##-------------------------------##  Single split implementation  ##-------------------------------#def single_split_SVM(split, prior=0.5):        DT, LT = split[0] # Train Data and Labels    DE, LE = split[1] # Test Data and Labels    Cs=numpy.logspace(-1, -1, num=1)  #For Normal Use    #Cs=numpy.logspace(-3, 1, num=30) #For Graphichs    minDCFGrapg=[]        for C in Cs:        S,LabelPredicted = SVM( DT, LT, DE, gamma=1.0, C=C, K=1.0, mode="linear")        minDCF = ev.computeMinDCF(LE, S, prior, numpy.array([[0,1],[1,0]]))        minDCFGrapg.append(minDCF)        print ("[Single_Split and Linear SVG] For C value: ", C,               " and Prior value equal to: ", prior,               " the minDCF value is: ", minDCF)            return minDCFGrapg, Cs